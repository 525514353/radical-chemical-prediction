{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2025-05-30T16:22:52.716644Z",
     "end_time": "2025-05-30T16:27:05.772740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDKit found. Advanced SMILES processing, similarity, and property calculation will be used.\n",
      "Using device: cuda\n",
      "Loading tokenizer from ./best_model_multi_eval_v3_correct_loss/...\n",
      "Loading base model 'google/flan-t5-base' and adapter from './best_model_multi_eval_v3_correct_loss/'...\n",
      "Model loaded successfully.\n",
      "Loading and preparing test data from './data/data'...\n",
      "Source test pairs: 508. Unique (pre-standardized) reactants with true products: 429\n"
     ]
    },
    {
     "data": {
      "text/plain": "Predicting Reactions:   0%|          | 0/508 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f7f59127a304b4fa9c26f8994695476"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Score Only (Original Ranking) Metrics ---\n",
      "Total Unique Input Reactants Processed: 429\n",
      "Top-1 Accuracy: 72.03%\n",
      "Top-3 Accuracy: 78.79%\n",
      "Top-5 Accuracy: 79.95%\n",
      "\n",
      "--- Comprehensive Score (Re-ranked from Top-15) Metrics ---\n",
      "Total Unique Input Reactants Processed: 429\n",
      "Top-1 Accuracy: 74.13%\n",
      "Top-3 Accuracy: 80.89%\n",
      "Top-5 Accuracy: 82.05%\n",
      "\n",
      "--- Improvement from Re-ranking ---\n",
      "Top-1 Improvement: +2.10%\n",
      "Top-3 Improvement: +2.10%\n",
      "Top-5 Improvement: +2.10%\n",
      "\n",
      "Results saved to ./comprehensive_reaction_prediction_results.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_from_disk, Dataset\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import PeftModel\n",
    "import numpy as np\n",
    "import traceback\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Attempt to import RDKit\n",
    "try:\n",
    "    from rdkit import Chem\n",
    "    from rdkit import RDLogger\n",
    "    from rdkit.DataStructs import TanimotoSimilarity\n",
    "    from rdkit.Chem.rdMolDescriptors import GetMorganFingerprintAsBitVect # ECFP\n",
    "    RDLogger.DisableLog('rdApp.*')\n",
    "    RDKIT_AVAILABLE = True\n",
    "    print(\"RDKit found. Advanced SMILES processing, similarity, and property calculation will be used.\")\n",
    "except ImportError:\n",
    "    RDKIT_AVAILABLE = False\n",
    "    print(\"RDKit not found. SMILES processing will be string-based, no fingerprint or advanced properties.\")\n",
    "    print(\"For better accuracy and features, please install RDKit: pip install rdkit-pypi\")\n",
    "\n",
    "# --- Configuration ---\n",
    "BASE_MODEL_NAME = \"google/flan-t5-base\"\n",
    "ADAPTER_MODEL_PATH = \"./best_model_multi_eval_v3_correct_loss/\"\n",
    "DATA_PATH = './data/data'\n",
    "OUTPUT_CSV_PATH = \"./comprehensive_reaction_prediction_results.csv\"\n",
    "\n",
    "NUM_RETURN_SEQUENCES = 20  # Generate 15 sequences for comprehensive ranking\n",
    "MAX_LENGTH_GENERATION = 256\n",
    "NUM_BEAMS = NUM_RETURN_SEQUENCES + 5  # Adjusted for 15 sequences\n",
    "TEMPERATURE = 1.0\n",
    "TOP_K = 50\n",
    "TOP_P = 0.95\n",
    "DO_SAMPLE = False\n",
    "\n",
    "# Scoring weights for comprehensive score\n",
    "MODEL_SCORE_WEIGHT = 0.3    # 模型排名权重\n",
    "VALIDITY_SCORE_WEIGHT = 0.1 # 化学有效性权重\n",
    "BALANCE_SCORE_WEIGHT = 0.6  # 原子平衡权重\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "FINGERPRINT_SIMILARITY_THRESHOLD = 1\n",
    "\n",
    "# --- Atom Balancing Functions ---\n",
    "def get_atom_counts_from_smiles(smiles: str) -> Counter:\n",
    "    \"\"\"\n",
    "    Extract atom counts from SMILES string using RDKit when available,\n",
    "    with fallback to regex-based parsing for cases with radicals or abbreviations.\n",
    "    \"\"\"\n",
    "    if not smiles or not isinstance(smiles, str):\n",
    "        return Counter()\n",
    "\n",
    "    smiles = smiles.strip()\n",
    "    if not smiles:\n",
    "        return Counter()\n",
    "\n",
    "    # First try RDKit if available\n",
    "    if RDKIT_AVAILABLE:\n",
    "        try:\n",
    "            # Try parsing with sanitization\n",
    "            mol = Chem.MolFromSmiles(smiles, sanitize=True)\n",
    "            if mol:\n",
    "                atom_counts = Counter()\n",
    "                for atom in mol.GetAtoms():\n",
    "                    symbol = atom.GetSymbol()\n",
    "                    atom_counts[symbol] += 1\n",
    "                return atom_counts\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            # Try parsing without sanitization for radicals\n",
    "            mol = Chem.MolFromSmiles(smiles, sanitize=False)\n",
    "            if mol:\n",
    "                atom_counts = Counter()\n",
    "                for atom in mol.GetAtoms():\n",
    "                    symbol = atom.GetSymbol()\n",
    "                    atom_counts[symbol] += 1\n",
    "                return atom_counts\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Fallback to regex-based parsing\n",
    "    return _regex_atom_count_fallback(smiles)\n",
    "\n",
    "def _regex_atom_count_fallback(smiles: str) -> Counter:\n",
    "    \"\"\"\n",
    "    Fallback method to extract atom counts using regex patterns.\n",
    "    Handles basic SMILES notation including some radical notations.\n",
    "    \"\"\"\n",
    "    atom_counts = Counter()\n",
    "\n",
    "    # Remove brackets for simplicity in counting, but keep track of charges and radicals\n",
    "    # Pattern to match atoms (including those in brackets)\n",
    "    # This pattern matches: [Element], [Element+], [Element-], [Element], Element\n",
    "    atom_pattern = r'\\[([A-Z][a-z]?)(?:[+-]?\\d*|\\.)*\\]|([A-Z][a-z]?)'\n",
    "\n",
    "    matches = re.findall(atom_pattern, smiles)\n",
    "\n",
    "    for match in matches:\n",
    "        # match is a tuple: (bracketed_atom, unbracketted_atom)\n",
    "        atom = match[0] if match[0] else match[1]\n",
    "        if atom:\n",
    "            # Handle common abbreviations\n",
    "            atom = _expand_atom_abbreviation(atom)\n",
    "            atom_counts[atom] += 1\n",
    "\n",
    "    # Handle explicit hydrogen counts in brackets like [CH3], [NH2], etc.\n",
    "    bracket_pattern = r'\\[([A-Z][a-z]?)H?(\\d*)[+-]?\\d*\\.?\\]'\n",
    "    bracket_matches = re.findall(bracket_pattern, smiles)\n",
    "\n",
    "    for atom, h_count in bracket_matches:\n",
    "        if h_count:\n",
    "            try:\n",
    "                h_num = int(h_count) if h_count else 1\n",
    "                atom_counts['H'] += h_num\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    return atom_counts\n",
    "\n",
    "def _expand_atom_abbreviation(atom: str) -> str:\n",
    "    \"\"\"\n",
    "    Expand common atom abbreviations to standard element symbols.\n",
    "    \"\"\"\n",
    "    abbreviations = {\n",
    "        'Me': 'C',  # Methyl - simplified to carbon\n",
    "        'Et': 'C',  # Ethyl - simplified to carbon\n",
    "        'Ph': 'C',  # Phenyl - simplified to carbon\n",
    "        'Ac': 'C',  # Acetyl - simplified to carbon\n",
    "        'Bn': 'C',  # Benzyl - simplified to carbon\n",
    "        'Bu': 'C',  # Butyl - simplified to carbon\n",
    "        'Pr': 'C',  # Propyl - simplified to carbon\n",
    "        'Tf': 'C',  # Trifluoromethyl - simplified (should include F but simplified here)\n",
    "        'Ts': 'C',  # Tosyl - simplified to carbon\n",
    "        'Boc': 'C', # tert-Butoxycarbonyl - simplified to carbon\n",
    "        'Cbz': 'C', # Carboxybenzyl - simplified to carbon\n",
    "    }\n",
    "    return abbreviations.get(atom, atom)\n",
    "\n",
    "def parse_multi_component_smiles(multi_smiles: str) -> list:\n",
    "    \"\"\"\n",
    "    Parse multi-component SMILES (separated by '.') into individual components.\n",
    "    \"\"\"\n",
    "    if not multi_smiles or not isinstance(multi_smiles, str):\n",
    "        return []\n",
    "\n",
    "    # Split by '.' to get individual components\n",
    "    components = [comp.strip() for comp in multi_smiles.split('.') if comp.strip()]\n",
    "    return components\n",
    "\n",
    "def check_atom_balance(reactant_smiles: str, product_smiles: str) -> dict:\n",
    "    \"\"\"\n",
    "    Check if the reaction is atom-balanced between reactants and products.\n",
    "\n",
    "    Args:\n",
    "        reactant_smiles: SMILES string of reactants (may be multi-component)\n",
    "        product_smiles: SMILES string of products (may be multi-component)\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "            'is_balanced': bool,\n",
    "            'reactant_atoms': Counter,\n",
    "            'product_atoms': Counter,\n",
    "            'missing_in_products': Counter,\n",
    "            'extra_in_products': Counter,\n",
    "            'balance_score': float  # 0.0 to 1.0, where 1.0 is perfectly balanced\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Parse multi-component SMILES\n",
    "    reactant_components = parse_multi_component_smiles(reactant_smiles)\n",
    "    product_components = parse_multi_component_smiles(product_smiles)\n",
    "\n",
    "    # Count atoms in reactants\n",
    "    reactant_atoms = Counter()\n",
    "    for component in reactant_components:\n",
    "        component_atoms = get_atom_counts_from_smiles(component)\n",
    "        reactant_atoms.update(component_atoms)\n",
    "\n",
    "    # Count atoms in products\n",
    "    product_atoms = Counter()\n",
    "    for component in product_components:\n",
    "        component_atoms = get_atom_counts_from_smiles(component)\n",
    "        product_atoms.update(component_atoms)\n",
    "\n",
    "    # Check balance\n",
    "    missing_in_products = reactant_atoms - product_atoms\n",
    "    extra_in_products = product_atoms - reactant_atoms\n",
    "\n",
    "    # Remove zero counts\n",
    "    missing_in_products = +missing_in_products  # This removes zero and negative counts\n",
    "    extra_in_products = +extra_in_products\n",
    "\n",
    "    is_balanced = len(missing_in_products) == 0 and len(extra_in_products) == 0\n",
    "\n",
    "    # Calculate balance score\n",
    "    total_reactant_atoms = sum(reactant_atoms.values())\n",
    "    total_imbalance = sum(missing_in_products.values()) + sum(extra_in_products.values())\n",
    "\n",
    "    if total_reactant_atoms == 0:\n",
    "        balance_score = 0.0\n",
    "    else:\n",
    "        balance_score = max(0.0, 1.0 - (total_imbalance / total_reactant_atoms))\n",
    "\n",
    "    return {\n",
    "        'is_balanced': is_balanced,\n",
    "        'reactant_atoms': reactant_atoms,\n",
    "        'product_atoms': product_atoms,\n",
    "        'missing_in_products': missing_in_products,\n",
    "        'extra_in_products': extra_in_products,\n",
    "        'balance_score': balance_score\n",
    "    }\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def canonicalize_smiles_rdkit(smiles: str, sanitize=True) -> str:\n",
    "    if not RDKIT_AVAILABLE or not smiles or not isinstance(smiles, str):\n",
    "        return str(smiles).strip() if isinstance(smiles, str) else \"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles, sanitize=sanitize)\n",
    "        if mol: return Chem.MolToSmiles(mol, canonical=True)\n",
    "        return smiles.strip()\n",
    "    except Exception:\n",
    "        if sanitize:\n",
    "            try:\n",
    "                mol_no_sanitize = Chem.MolFromSmiles(smiles, sanitize=False)\n",
    "                if mol_no_sanitize:\n",
    "                    Chem.SanitizeMol(mol_no_sanitize, Chem.SanitizeFlags.SANITIZE_FINDRADICALS | Chem.SanitizeFlags.SANITIZE_SETAROMATICITY | Chem.SanitizeFlags.SANITIZE_SETHYBRIDIZATION | Chem.SanitizeFlags.SANITIZE_SYMMRINGS, catchErrors=True)\n",
    "                    return Chem.MolToSmiles(mol_no_sanitize, canonical=True)\n",
    "            except Exception: pass\n",
    "        return smiles.strip()\n",
    "\n",
    "def score_chemical_validity(smiles_to_score: str) -> float:\n",
    "    \"\"\"Scores the chemical validity of a SMILES string (preferably raw model output).\"\"\"\n",
    "    if not RDKIT_AVAILABLE or not smiles_to_score or not isinstance(smiles_to_score, str):\n",
    "        return 0.0\n",
    "    try:\n",
    "        # Try to parse with sanitization first for a stricter validity check\n",
    "        mol = Chem.MolFromSmiles(smiles_to_score, sanitize=True)\n",
    "        if mol: return 1.0\n",
    "        # If strict sanitization fails, try less strict parsing\n",
    "        mol_no_sanitize = Chem.MolFromSmiles(smiles_to_score, sanitize=False)\n",
    "        if mol_no_sanitize: return 0.5 # Parsable but maybe not \"fully\" valid by strict rules\n",
    "        return 0.1 # Not even parsable without sanitization\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def robust_smiles_match(raw_predicted_smiles: str, standardized_true_products_set: set) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if the standardized form of raw_predicted_smiles matches any SMILES\n",
    "    in standardized_true_products_set.\n",
    "    Uses multi-component standardization for prediction and optional fingerprint fallback.\n",
    "    \"\"\"\n",
    "    if not raw_predicted_smiles or not isinstance(raw_predicted_smiles, str):\n",
    "        return False\n",
    "\n",
    "    standardized_prediction = canonicalize_smiles_rdkit(raw_predicted_smiles)\n",
    "    if not standardized_prediction: # If standardization results in empty string\n",
    "        return False\n",
    "\n",
    "    # 1. Direct match of standardized forms\n",
    "    if standardized_prediction in standardized_true_products_set:\n",
    "        return True\n",
    "\n",
    "    # 2. Fingerprint similarity (if RDKit available and direct match failed)\n",
    "    if RDKIT_AVAILABLE:\n",
    "        try:\n",
    "            pred_mol = Chem.MolFromSmiles(standardized_prediction)\n",
    "            if not pred_mol: # If standardized isn't parsable, try raw\n",
    "                pred_mol = Chem.MolFromSmiles(raw_predicted_smiles)\n",
    "\n",
    "            if not pred_mol: # If neither form is parsable\n",
    "                return False\n",
    "\n",
    "            pred_fp = GetMorganFingerprintAsBitVect(pred_mol, 2, nBits=2048)\n",
    "\n",
    "            for true_s_standardized in standardized_true_products_set:\n",
    "                true_mol = Chem.MolFromSmiles(true_s_standardized)\n",
    "                if not true_mol: continue\n",
    "\n",
    "                true_fp = GetMorganFingerprintAsBitVect(true_mol, 2, nBits=2048)\n",
    "                similarity = TanimotoSimilarity(pred_fp, true_fp)\n",
    "                if similarity >= FINGERPRINT_SIMILARITY_THRESHOLD:\n",
    "                    return True\n",
    "        except Exception:\n",
    "            pass\n",
    "    return False\n",
    "\n",
    "def group_true_products_for_eval_assuming_standardized_input(dataset: Dataset) -> dict:\n",
    "    reactant_to_products_map = {}\n",
    "    for example in tqdm(dataset, desc=\"Grouping pre-standardized true products\", disable=True):\n",
    "        reactant_std = str(example.get('reactant', '')).strip()\n",
    "        product_std = str(example.get('product', '')).strip()\n",
    "        if not reactant_std or not product_std: continue\n",
    "        if reactant_std not in reactant_to_products_map:\n",
    "            reactant_to_products_map[reactant_std] = set()\n",
    "        reactant_to_products_map[reactant_std].add(product_std)\n",
    "    return reactant_to_products_map\n",
    "\n",
    "# --- Main Prediction Script ---\n",
    "def predict_and_evaluate():\n",
    "    print(f\"Loading tokenizer from {ADAPTER_MODEL_PATH}...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(ADAPTER_MODEL_PATH, use_fast=True)\n",
    "    print(f\"Loading base model '{BASE_MODEL_NAME}' and adapter from '{ADAPTER_MODEL_PATH}'...\")\n",
    "    try:\n",
    "        quantization_config_bnb = BitsAndBytesConfig(\n",
    "            load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "        base_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "            BASE_MODEL_NAME, quantization_config=quantization_config_bnb, device_map={\"\":DEVICE}\n",
    "        )\n",
    "        base_model.resize_token_embeddings(len(tokenizer))\n",
    "        model = PeftModel.from_pretrained(base_model, ADAPTER_MODEL_PATH)\n",
    "        model.eval(); model.to(DEVICE)\n",
    "        print(\"Model loaded successfully.\")\n",
    "    except Exception as e: print(f\"Error loading model: {e}\"); traceback.print_exc(); return\n",
    "\n",
    "    model.config.bos_token_id = tokenizer.bos_token_id\n",
    "    model.config.eos_token_id = tokenizer.eos_token_id\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    model.config.decoder_start_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    print(f\"Loading and preparing test data from '{DATA_PATH}'...\")\n",
    "    try:\n",
    "        raw_dataset = load_from_disk(DATA_PATH)\n",
    "        test_data_raw_pairs = raw_dataset['test']\n",
    "        true_products_lookup_map = group_true_products_for_eval_assuming_standardized_input(test_data_raw_pairs)\n",
    "        print(f\"Source test pairs: {len(test_data_raw_pairs)}. Unique (pre-standardized) reactants with true products: {len(true_products_lookup_map)}\")\n",
    "    except Exception as e: print(f\"Error loading or processing data: {e}\"); traceback.print_exc(); return\n",
    "\n",
    "    results_list = []\n",
    "    predicted_reactants_from_input = set()\n",
    "\n",
    "    # For model-only accuracy tracking (only top1, top3, top5)\n",
    "    model_only_results = {\"top1\": 0, \"top3\": 0, \"top5\": 0}\n",
    "\n",
    "    for raw_example in tqdm(test_data_raw_pairs, desc=\"Predicting Reactions\"):\n",
    "        original_reactant_smiles = str(raw_example.get('reactant', '')).strip()\n",
    "        if not original_reactant_smiles: continue\n",
    "\n",
    "        if original_reactant_smiles in predicted_reactants_from_input:\n",
    "            continue\n",
    "        predicted_reactants_from_input.add(original_reactant_smiles)\n",
    "\n",
    "        inputs = tokenizer(original_reactant_smiles, return_tensors=\"pt\", max_length=MAX_LENGTH_GENERATION, truncation=True)\n",
    "        input_ids = inputs.input_ids.to(DEVICE)\n",
    "        attention_mask = inputs.attention_mask.to(DEVICE)\n",
    "\n",
    "        true_standardized_products_set = true_products_lookup_map.get(original_reactant_smiles, set())\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                outputs = model.generate(\n",
    "                    input_ids=input_ids, attention_mask=attention_mask,\n",
    "                    max_length=MAX_LENGTH_GENERATION, num_return_sequences=NUM_RETURN_SEQUENCES,\n",
    "                    num_beams=NUM_BEAMS, do_sample=DO_SAMPLE,\n",
    "                    temperature=TEMPERATURE if DO_SAMPLE else 1.0,\n",
    "                    top_k=TOP_K if DO_SAMPLE else None, top_p=TOP_P if DO_SAMPLE else None,\n",
    "                    early_stopping=True, eos_token_id=model.config.eos_token_id,\n",
    "                    pad_token_id=model.config.pad_token_id,\n",
    "                    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    "                    return_dict_in_generate=True,\n",
    "                    output_scores=True\n",
    "                )\n",
    "\n",
    "            generated_ids = outputs.sequences\n",
    "            raw_predicted_smiles_batch = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "            # First, evaluate with original model ranking (for comparison)\n",
    "            original_order_std_predictions = []\n",
    "            seen_orig = set()\n",
    "            for pred_smiles_raw in raw_predicted_smiles_batch:\n",
    "                standardized_pred = canonicalize_smiles_rdkit(pred_smiles_raw)\n",
    "                if standardized_pred and standardized_pred not in seen_orig:\n",
    "                    original_order_std_predictions.append(standardized_pred)\n",
    "                    seen_orig.add(standardized_pred)\n",
    "\n",
    "            # Evaluate model-only accuracy (only top1, top3, top5)\n",
    "            if true_standardized_products_set:\n",
    "                if original_order_std_predictions and robust_smiles_match(original_order_std_predictions[0], true_standardized_products_set):\n",
    "                    model_only_results[\"top1\"] += 1\n",
    "                if any(robust_smiles_match(p, true_standardized_products_set) for p in original_order_std_predictions[:3]):\n",
    "                    model_only_results[\"top3\"] += 1\n",
    "                if any(robust_smiles_match(p, true_standardized_products_set) for p in original_order_std_predictions[:5]):\n",
    "                    model_only_results[\"top5\"] += 1\n",
    "\n",
    "            # Now proceed with comprehensive scoring\n",
    "            predictions_data = []\n",
    "\n",
    "            for i, pred_smiles_raw in enumerate(raw_predicted_smiles_batch):\n",
    "                # Model score: higher rank (lower index) gets higher score\n",
    "                model_score = 1.0 - (i / NUM_RETURN_SEQUENCES)\n",
    "\n",
    "                # Standardize prediction\n",
    "                standardized_pred = canonicalize_smiles_rdkit(pred_smiles_raw)\n",
    "\n",
    "                # Calculate validity score\n",
    "                validity_score = score_chemical_validity(pred_smiles_raw)\n",
    "\n",
    "                # Calculate atom balance score\n",
    "                balance_score = 0.0\n",
    "                if standardized_pred:\n",
    "                    balance_result = check_atom_balance(original_reactant_smiles, standardized_pred)\n",
    "                    balance_score = balance_result['balance_score']\n",
    "\n",
    "                # Calculate comprehensive score\n",
    "                comprehensive_score = (model_score * MODEL_SCORE_WEIGHT +\n",
    "                                     validity_score * VALIDITY_SCORE_WEIGHT +\n",
    "                                     balance_score * BALANCE_SCORE_WEIGHT)\n",
    "\n",
    "                predictions_data.append({\n",
    "                    'raw_smiles': pred_smiles_raw,\n",
    "                    'standardized_smiles': standardized_pred,\n",
    "                    'model_score': model_score,\n",
    "                    'validity_score': validity_score,\n",
    "                    'balance_score': balance_score,\n",
    "                    'comprehensive_score': comprehensive_score\n",
    "                })\n",
    "\n",
    "            # Sort by comprehensive score (descending)\n",
    "            predictions_data.sort(key=lambda x: x['comprehensive_score'], reverse=True)\n",
    "\n",
    "            # Only keep top 5 results for CSV output\n",
    "            top5_predictions = predictions_data[:5]\n",
    "\n",
    "            # Prepare result structure (only top5 for CSV)\n",
    "            current_result = {\n",
    "                \"input_reactant_smiles\": original_reactant_smiles,\n",
    "                \"true_products_standardized_list_str\": '; '.join(sorted(list(true_standardized_products_set))),\n",
    "                \"generated_smiles_raw_list\": [pred['raw_smiles'] for pred in top5_predictions],\n",
    "                \"generated_smiles_standardized_list\": [pred['standardized_smiles'] for pred in top5_predictions],\n",
    "                \"model_scores_list\": [pred['model_score'] for pred in top5_predictions],\n",
    "                \"validity_scores_list\": [pred['validity_score'] for pred in top5_predictions],\n",
    "                \"balance_scores_list\": [pred['balance_score'] for pred in top5_predictions],\n",
    "                \"comprehensive_scores_list\": [pred['comprehensive_score'] for pred in top5_predictions],\n",
    "                \"top1_match\": False, \"top3_match\": False, \"top5_match\": False\n",
    "            }\n",
    "\n",
    "            # Evaluate top-N matches based on re-ranked results (only top1, top3, top5)\n",
    "            unique_std_predictions = []\n",
    "            seen_preds_for_topn = set()\n",
    "            for pred in predictions_data:  # Use all predictions for evaluation, not just top5\n",
    "                if pred['standardized_smiles'] and pred['standardized_smiles'] not in seen_preds_for_topn:\n",
    "                    unique_std_predictions.append(pred['standardized_smiles'])\n",
    "                    seen_preds_for_topn.add(pred['standardized_smiles'])\n",
    "\n",
    "            if true_standardized_products_set:\n",
    "                if unique_std_predictions and robust_smiles_match(unique_std_predictions[0], true_standardized_products_set):\n",
    "                    current_result[\"top1_match\"] = True\n",
    "                if any(robust_smiles_match(p, true_standardized_products_set) for p in unique_std_predictions[:3]):\n",
    "                    current_result[\"top3_match\"] = True\n",
    "                if any(robust_smiles_match(p, true_standardized_products_set) for p in unique_std_predictions[:5]):\n",
    "                    current_result[\"top5_match\"] = True\n",
    "\n",
    "        except Exception as e_gen:\n",
    "            print(f\"Error during generation for reactant '{original_reactant_smiles}': {e_gen}\")\n",
    "            current_result = {\n",
    "                \"input_reactant_smiles\": original_reactant_smiles,\n",
    "                \"true_products_standardized_list_str\": '; '.join(sorted(list(true_standardized_products_set))),\n",
    "                \"generated_smiles_raw_list\": [\"ERROR_GENERATING\"] * 5,  # Only 5 for CSV\n",
    "                \"generated_smiles_standardized_list\": [\"ERROR_GENERATING\"] * 5,  # Only 5 for CSV\n",
    "                \"model_scores_list\": [0.0] * 5,  # Only 5 for CSV\n",
    "                \"validity_scores_list\": [0.0] * 5,  # Only 5 for CSV\n",
    "                \"balance_scores_list\": [0.0] * 5,  # Only 5 for CSV\n",
    "                \"comprehensive_scores_list\": [0.0] * 5,  # Only 5 for CSV\n",
    "                \"top1_match\": False, \"top3_match\": False, \"top5_match\": False\n",
    "            }\n",
    "\n",
    "        results_list.append(current_result)\n",
    "        del input_ids, attention_mask; gc.collect()\n",
    "        if 'outputs' in locals(): del outputs\n",
    "        if DEVICE.type == 'cuda': torch.cuda.empty_cache()\n",
    "\n",
    "    num_total_unique_reactants_predicted = len(predicted_reactants_from_input)\n",
    "    if num_total_unique_reactants_predicted == 0:\n",
    "        print(\"No reactants were processed. Check data or logic.\"); return\n",
    "\n",
    "    # Print model-only accuracy (original ranking) - only top1, top3, top5\n",
    "    model_only_top1 = model_only_results[\"top1\"] / num_total_unique_reactants_predicted * 100\n",
    "    model_only_top3 = model_only_results[\"top3\"] / num_total_unique_reactants_predicted * 100\n",
    "    model_only_top5 = model_only_results[\"top5\"] / num_total_unique_reactants_predicted * 100\n",
    "\n",
    "    print(\"\\n--- Model Score Only (Original Ranking) Metrics ---\")\n",
    "    print(f\"Total Unique Input Reactants Processed: {num_total_unique_reactants_predicted}\")\n",
    "    print(f\"Top-1 Accuracy: {model_only_top1:.2f}%\")\n",
    "    print(f\"Top-3 Accuracy: {model_only_top3:.2f}%\")\n",
    "    print(f\"Top-5 Accuracy: {model_only_top5:.2f}%\")\n",
    "\n",
    "    # Print comprehensive score accuracy (re-ranked) - only top1, top3, top5\n",
    "    overall_top1 = sum(r[\"top1_match\"] for r in results_list) / num_total_unique_reactants_predicted * 100\n",
    "    overall_top3 = sum(r[\"top3_match\"] for r in results_list) / num_total_unique_reactants_predicted * 100\n",
    "    overall_top5 = sum(r[\"top5_match\"] for r in results_list) / num_total_unique_reactants_predicted * 100\n",
    "\n",
    "    print(\"\\n--- Comprehensive Score (Re-ranked from Top-15) Metrics ---\")\n",
    "    print(f\"Total Unique Input Reactants Processed: {num_total_unique_reactants_predicted}\")\n",
    "    print(f\"Top-1 Accuracy: {overall_top1:.2f}%\")\n",
    "    print(f\"Top-3 Accuracy: {overall_top3:.2f}%\")\n",
    "    print(f\"Top-5 Accuracy: {overall_top5:.2f}%\")\n",
    "\n",
    "    print(\"\\n--- Improvement from Re-ranking ---\")\n",
    "    print(f\"Top-1 Improvement: {overall_top1 - model_only_top1:+.2f}%\")\n",
    "    print(f\"Top-3 Improvement: {overall_top3 - model_only_top3:+.2f}%\")\n",
    "    print(f\"Top-5 Improvement: {overall_top5 - model_only_top5:+.2f}%\")\n",
    "\n",
    "    df_results = pd.DataFrame(results_list)\n",
    "    for col in [\"generated_smiles_raw_list\", \"generated_smiles_standardized_list\",\n",
    "                \"model_scores_list\", \"validity_scores_list\", \"balance_scores_list\", \"comprehensive_scores_list\"]:\n",
    "        df_results[col] = df_results[col].apply(lambda x: '; '.join(map(str, x)) if isinstance(x, list) else x)\n",
    "\n",
    "    try:\n",
    "        df_results.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "        print(f\"\\nResults saved to {OUTPUT_CSV_PATH}\")\n",
    "    except Exception as e_csv: print(f\"Error saving results to CSV: {e_csv}\")\n",
    "\n",
    "    # Cleanup\n",
    "    del model, base_model, tokenizer\n",
    "    gc.collect()\n",
    "    if DEVICE.type == 'cuda': torch.cuda.empty_cache()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predict_and_evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
