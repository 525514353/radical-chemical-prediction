{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data...\n",
      "Raw training samples: 4770\n",
      "Raw source samples for validation: 508\n",
      "Grouped validation samples (reactants): 429\n",
      "trainable params: 169,869,312 || all params: 417,447,168 || trainable%: 40.6924\n",
      "Tokenizing training data...\n",
      "Tokenizing validation data...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/429 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "098298e08c4942cb8c2efea93ac64614"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_from_disk, Dataset, concatenate_datasets\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "import random\n",
    "\n",
    "\n",
    "# --- Helper function for creating grouped validation data ---\n",
    "def group_products_for_validation(dataset: Dataset) -> Dataset:\n",
    "    reactant_to_products = {}\n",
    "    for example in dataset:\n",
    "        r = example['reactant']\n",
    "        p = example['product']\n",
    "        if r not in reactant_to_products:\n",
    "            reactant_to_products[r] = []\n",
    "        if p not in reactant_to_products[r]:\n",
    "            reactant_to_products[r].append(p)\n",
    "    new_data = [{'reactant': r, 'products': ps} for r, ps in reactant_to_products.items() if ps] # Ensure products list is not empty\n",
    "    return Dataset.from_list(new_data)\n",
    "\n",
    "# --- Load Data ---\n",
    "print(\"Loading raw data...\")\n",
    "df_raw = load_from_disk('./data/data')\n",
    "\n",
    "train_dataset_raw = df_raw['train']\n",
    "validation_source_dataset_raw = df_raw['test']\n",
    "\n",
    "print(f\"Raw training samples: {len(train_dataset_raw)}\")\n",
    "print(f\"Raw source samples for validation: {len(validation_source_dataset_raw)}\")\n",
    "\n",
    "validation_dataset_grouped = group_products_for_validation(validation_source_dataset_raw)\n",
    "print(f\"Grouped validation samples (reactants): {len(validation_dataset_grouped)}\")\n",
    "\n",
    "# --- Configuration ---\n",
    "max_seq_length = 256\n",
    "MODEL_NAME = \"google/flan-t5-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"smiles_tokenizer\", use_fast=True)\n",
    "\n",
    "tokenizer.backend_tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"$A </s>\",\n",
    "    pair=\"$A </s> $B </s>\",\n",
    "    special_tokens=[(\"</s>\", tokenizer.eos_token_id)],\n",
    ")\n",
    "\n",
    "quantization_config_bnb = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    MODEL_NAME, quantization_config=quantization_config_bnb, device_map=\"auto\"\n",
    ")\n",
    "\n",
    "r_lora = 1536\n",
    "peft_config = LoraConfig(\n",
    "    r=r_lora, lora_alpha=2 * r_lora, target_modules=['q', 'v'],\n",
    "    lora_dropout=0.1, bias=\"none\", task_type=\"SEQ_2_SEQ_LM\"\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "model.config.bos_token_id = tokenizer.bos_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.decoder_start_token_id = tokenizer.pad_token_id\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "\n",
    "# --- Preprocessing Functions ---\n",
    "def preprocess_train_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"reactant\"],\n",
    "        text_target=examples[\"product\"],  # Êõø‰ª£ as_target_tokenizer\n",
    "        max_length=max_seq_length,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "def returnlength(example):\n",
    "    return  {'length':len(example['labels'])}\n",
    "\n",
    "\n",
    "def preprocess_eval_function(examples):\n",
    "    reactant_inputs = tokenizer(\n",
    "        examples[\"reactant\"], max_length=max_seq_length, truncation=True, padding=\"do_not_pad\"\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": reactant_inputs[\"input_ids\"],\n",
    "        \"attention_mask\": reactant_inputs[\"attention_mask\"],\n",
    "        \"all_target_texts\": examples[\"products\"]\n",
    "    }\n",
    "\n",
    "print(\"Tokenizing training data...\")\n",
    "tokenized_train_dataset = train_dataset_raw.map(\n",
    "    preprocess_train_function, batched=True, remove_columns=train_dataset_raw.column_names\n",
    ")\n",
    "tokenized_train_dataset = tokenized_train_dataset.map(\n",
    "    returnlength)\n",
    "\n",
    "print(\"Tokenizing validation data...\")\n",
    "tokenized_eval_dataset = validation_dataset_grouped.map(\n",
    "    preprocess_eval_function, batched=True, remove_columns=validation_dataset_grouped.column_names\n",
    ")\n",
    "\n",
    "# --- Data Collators ---\n",
    "train_data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer, model=model, padding=\"longest\", max_length=max_seq_length,\n",
    "    pad_to_multiple_of=8 if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8 else None\n",
    ")\n",
    "\n",
    "# Modified eval collator: no longer creates initial_decoder_input_ids\n",
    "def custom_eval_data_collator(features):\n",
    "    input_ids = [feature[\"input_ids\"] for feature in features]\n",
    "    attention_mask = [feature[\"attention_mask\"] for feature in features]\n",
    "    all_target_texts_list = [feature[\"all_target_texts\"] for feature in features]\n",
    "\n",
    "    # Pad only the encoder inputs (reactant)\n",
    "    batch_encoder_inputs = tokenizer.pad(\n",
    "        {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n",
    "        padding=\"longest\",\n",
    "        max_length=max_seq_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    # The rest (decoder_input_ids, labels for loss) will be handled on-the-fly in the eval loop\n",
    "    # for each target product.\n",
    "    batch_encoder_inputs[\"all_target_texts\"] = all_target_texts_list\n",
    "    return batch_encoder_inputs\n",
    "\n",
    "\n",
    "# --- DataLoaders ---\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 24 # Smaller due to multiple forward passes per item in validation\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_train_dataset, batch_size=train_batch_size, shuffle=True,\n",
    "    collate_fn=train_data_collator, pin_memory=True\n",
    ")\n",
    "eval_dataloader = DataLoader( # For validation\n",
    "    tokenized_eval_dataset, batch_size=eval_batch_size, # Effective batch size for model forward pass is 1 in the inner loop\n",
    "    collate_fn=custom_eval_data_collator, pin_memory=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-11T14:17:04.047906Z",
     "end_time": "2025-06-11T14:17:12.394733Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 Input IDs: tensor([ 83, 152, 483,  11, 109,   3,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0])\n",
      "attention mask for inputtensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Decoded Input: CCC(F)C(Cl)(Cl)Cl.Cl</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "Sample 0 Labels: tensor([ 109,   11,  115,  149,  147,  483,    3, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100])\n",
      "Decoded Labels: ['Cl', '.', '[CH2]', 'CC(', 'F)', 'C(Cl)(Cl)Cl', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Sample 0 Decoder Input IDs: tensor([  0, 109,  11, 115, 149, 147, 483,   3,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0])\n",
      "Decoded Decoder Input IDs: ['<pad>', 'Cl', '.', '[CH2]', 'CC(', 'F)', 'C(Cl)(Cl)Cl', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Model's decoder_start_token_id: 0\n",
      "Tokenizer's pad_token_id: 0\n",
      "length:tensor([ 7,  4,  5,  4,  5,  6,  4, 19,  6,  3, 12, 44, 11,  3,  7,  4,  9,  8,\n",
      "         6,  7,  3,  7,  4,  9,  7,  5, 10,  5,  7,  6,  5,  5])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%test input\n",
    "for batch in train_dataloader:\n",
    "    print(f\"Sample 0 Input IDs: {batch['input_ids'][0]}\")\n",
    "    print(f\"attention mask for input{batch['attention_mask'][0]}\")\n",
    "    print(f\"Decoded Input: {tokenizer.decode(batch['input_ids'][0], skip_special_tokens=False)}\")\n",
    "    print(f\"Sample 0 Labels: {batch['labels'][0]}\")\n",
    "    print(f\"Decoded Labels: {tokenizer.convert_ids_to_tokens([l if l != -100 else tokenizer.pad_token_id for l in batch['labels'][0]], skip_special_tokens=False)}\") # Handle -100 for decoding\n",
    "    print(f\"Sample 0 Decoder Input IDs: {batch['decoder_input_ids'][0]}\")\n",
    "    print(f\"Decoded Decoder Input IDs: {tokenizer.convert_ids_to_tokens(batch['decoder_input_ids'][0], skip_special_tokens=False)}\")\n",
    "    print(f\"Model's decoder_start_token_id: {model.config.decoder_start_token_id}\")\n",
    "    print(f\"Tokenizer's pad_token_id: {tokenizer.pad_token_id}\")\n",
    "    print(f\"length:{batch['length']}\")\n",
    "    break\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-11T14:17:12.395733Z",
     "end_time": "2025-06-11T14:17:12.440757Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from bitsandbytes.optim import AdamW8bit\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import gc\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import get_scheduler\n",
    "from rouge_score import rouge_scorer\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "# --- Evaluation Metrics Calculation ---\n",
    "def calculate_metrics_on_validation(model, tokenizer, eval_dataloader, device, rouge_calculator, progress_bar=None,\n",
    "                                   max_rouge_samples=1000, calculate_rouge=False):\n",
    "    model.eval()\n",
    "    total_min_val_loss_sum = 0.0\n",
    "    total_max_rouge_l_sum = 0.0\n",
    "    val_loss_items_count = 0\n",
    "    rouge_samples_processed = 0\n",
    "    all_min_losses_for_perplexity = []\n",
    "\n",
    "    with torch.autograd.set_detect_anomaly(False):\n",
    "        for batch_data in eval_dataloader:\n",
    "            batch_encoder_input_ids = batch_data[\"input_ids\"].to(device, non_blocking=True)\n",
    "            batch_encoder_attention_mask = batch_data[\"attention_mask\"].to(device, non_blocking=True)\n",
    "            batch_all_target_texts = batch_data[\"all_target_texts\"]\n",
    "\n",
    "            # Only generate predictions for RougeL if we're calculating it this epoch\n",
    "            generated_ids_for_rouge = None\n",
    "            if calculate_rouge and rouge_samples_processed < max_rouge_samples:\n",
    "                num_to_gen_for_rouge = min(batch_encoder_input_ids.size(0), max_rouge_samples - rouge_samples_processed)\n",
    "                if num_to_gen_for_rouge > 0:\n",
    "                    with torch.no_grad(), torch.amp.autocast(dtype=torch.bfloat16, device_type=\"cuda\", enabled=torch.cuda.is_available()):\n",
    "                        generated_ids_for_rouge = model.generate(\n",
    "                            input_ids=batch_encoder_input_ids[:num_to_gen_for_rouge],\n",
    "                            attention_mask=batch_encoder_attention_mask[:num_to_gen_for_rouge],\n",
    "                            max_length=max_seq_length, num_beams=3, early_stopping=True,\n",
    "                            bos_token_id=model.config.bos_token_id,eos_token_id=model.config.eos_token_id, pad_token_id=model.config.pad_token_id,\n",
    "                            decoder_start_token_id=model.config.decoder_start_token_id\n",
    "                        )\n",
    "\n",
    "            # Iterate through each reactant in the batch\n",
    "            for i in range(batch_encoder_input_ids.size(0)):\n",
    "                reactant_input_ids = batch_encoder_input_ids[i:i+1]\n",
    "                reactant_attention_mask = batch_encoder_attention_mask[i:i+1]\n",
    "                item_possible_target_texts = batch_all_target_texts[i]\n",
    "\n",
    "                if not item_possible_target_texts or all(not t.strip() for t in item_possible_target_texts):\n",
    "                    if calculate_rouge and rouge_samples_processed < max_rouge_samples and i < (num_to_gen_for_rouge if 'num_to_gen_for_rouge' in locals() else 0):\n",
    "                        rouge_samples_processed += 1\n",
    "                    continue\n",
    "\n",
    "                # --- Calculate Min Loss (multiple forward passes per reactant) ---\n",
    "                min_loss_for_item_numeric = float('inf')\n",
    "                for target_text in item_possible_target_texts:\n",
    "                    if not target_text.strip(): continue\n",
    "\n",
    "                    tokenized_target = tokenizer(\n",
    "                        target_text, max_length=max_seq_length,\n",
    "                        padding=\"longest\", truncation=True, return_tensors=\"pt\"\n",
    "                    )\n",
    "                    target_labels_single = tokenized_target.input_ids.to(device)\n",
    "\n",
    "                    decoder_input_ids_single = model.prepare_decoder_input_ids_from_labels(labels=target_labels_single.clone())\n",
    "\n",
    "                    with torch.no_grad(), torch.amp.autocast(dtype=torch.bfloat16, device_type=\"cuda\", enabled=torch.cuda.is_available()):\n",
    "                        outputs_per_target = model(\n",
    "                            input_ids=reactant_input_ids,\n",
    "                            attention_mask=reactant_attention_mask,\n",
    "                            decoder_input_ids=decoder_input_ids_single,\n",
    "                            use_cache=False\n",
    "                        )\n",
    "                        logits_per_target = outputs_per_target.logits\n",
    "\n",
    "                    output_seq_len = logits_per_target.size(1)\n",
    "                    aligned_target_labels = torch.full((1, output_seq_len), tokenizer.pad_token_id, dtype=torch.long, device=device)\n",
    "                    actual_target_len = min(output_seq_len, target_labels_single.size(1))\n",
    "                    aligned_target_labels[0, :actual_target_len] = target_labels_single[0, :actual_target_len]\n",
    "                    aligned_target_labels[aligned_target_labels == tokenizer.pad_token_id] = -100\n",
    "\n",
    "                    loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
    "                    current_loss_value = loss_fct(\n",
    "                        logits_per_target.view(-1, logits_per_target.size(-1)),\n",
    "                        aligned_target_labels.view(-1)\n",
    "                    )\n",
    "                    min_loss_for_item_numeric = min(min_loss_for_item_numeric, current_loss_value.item())\n",
    "                    del outputs_per_target, logits_per_target, tokenized_target, target_labels_single, decoder_input_ids_single, aligned_target_labels, current_loss_value\n",
    "\n",
    "                if min_loss_for_item_numeric != float('inf'):\n",
    "                    total_min_val_loss_sum += min_loss_for_item_numeric\n",
    "                    all_min_losses_for_perplexity.append(min_loss_for_item_numeric)\n",
    "                    val_loss_items_count += 1\n",
    "\n",
    "                # --- Calculate Max ROUGE (only if requested) ---\n",
    "                if calculate_rouge and rouge_samples_processed < max_rouge_samples and generated_ids_for_rouge is not None and i < len(generated_ids_for_rouge):\n",
    "                    generated_text = tokenizer.decode(generated_ids_for_rouge[i], skip_special_tokens=True)\n",
    "                    current_max_rouge_l_for_item = 0.0\n",
    "                    for ref_text in item_possible_target_texts:\n",
    "                        if not ref_text.strip(): continue\n",
    "                        try:\n",
    "                            rouge_scores = rouge_calculator.score(ref_text, generated_text)\n",
    "                            current_max_rouge_l_for_item = max(current_max_rouge_l_for_item, rouge_scores['rougeL'].fmeasure)\n",
    "                        except Exception: pass\n",
    "                    total_max_rouge_l_sum += current_max_rouge_l_for_item\n",
    "                    rouge_samples_processed += 1\n",
    "\n",
    "            if 'generated_ids_for_rouge' in locals() and generated_ids_for_rouge is not None:\n",
    "                del generated_ids_for_rouge\n",
    "            del batch_encoder_input_ids, batch_encoder_attention_mask, batch_all_target_texts\n",
    "            gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    avg_min_val_loss = total_min_val_loss_sum / val_loss_items_count if val_loss_items_count > 0 else float('inf')\n",
    "\n",
    "    # Calculate Rouge-L and perplexity only if requested or needed\n",
    "    avg_max_rouge_l = 0.0\n",
    "    if calculate_rouge:\n",
    "        avg_max_rouge_l = total_max_rouge_l_sum / rouge_samples_processed if rouge_samples_processed > 0 else 0.0\n",
    "\n",
    "    valid_losses_for_ppl = [l for l in all_min_losses_for_perplexity if l > 0 and l != float('inf')]\n",
    "    perplexity = math.exp(sum(valid_losses_for_ppl) / len(valid_losses_for_ppl)) if valid_losses_for_ppl else float('inf')\n",
    "\n",
    "    metrics = {\"loss\": avg_min_val_loss, \"perplexity\": perplexity}\n",
    "    if calculate_rouge:\n",
    "        metrics[\"rouge_l\"] = avg_max_rouge_l\n",
    "\n",
    "    # Display validation metrics based on what was calculated\n",
    "    if progress_bar:\n",
    "        status_msg = f\"Validation - Loss: {metrics['loss']:.4f}, PPL: {metrics['perplexity']:.2f}\"\n",
    "        if calculate_rouge:\n",
    "            status_msg += f\", ROUGE-L: {metrics['rouge_l']:.4f} ({rouge_samples_processed} samples)\"\n",
    "        else:\n",
    "            status_msg += f\" (ROUGE not calculated this epoch)\"\n",
    "        progress_bar.write(status_msg)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# --- Scheduled Sampling Function ---\n",
    "def get_scheduled_sampling_ratio(epoch, num_epochs, strategy=\"linear\"):\n",
    "    \"\"\"\n",
    "    ËÆ°ÁÆóscheduled samplingÁöÑÊØî‰æã\n",
    "    epoch: ÂΩìÂâçepoch\n",
    "    num_epochs: ÊÄªepochÊï∞\n",
    "    strategy: Á≠ñÁï•Á±ªÂûãÔºåÂèØ‰ª•ÊòØlinearÊàñinverse_sigmoid\n",
    "\n",
    "    ËøîÂõûÂÄº: ‰ΩøÁî®ÁúüÂÆûÊ†áÁ≠æ(teacher forcing)ÁöÑÊ¶ÇÁéá\n",
    "    \"\"\"\n",
    "    if strategy == \"linear\":\n",
    "        # Á∫øÊÄßË°∞ÂáèÔºö‰ªé1.0Âà∞0.0ÁöÑÊ¶ÇÁéá‰ΩøÁî®teacher forcing\n",
    "        return max(0.0, 1.0 - (epoch - 1) / (num_epochs * 0.75))\n",
    "    elif strategy == \"inverse_sigmoid\":\n",
    "        # Inverse sigmoidË°∞ÂáèÔºöÊèê‰æõÊõ¥Âπ≥ÊªëÁöÑË°∞ÂáèÊõ≤Á∫ø\n",
    "        k = num_epochs * 0.2  # ÊéßÂà∂Ë°∞ÂáèÈÄüÂ∫¶ÁöÑÂèÇÊï∞\n",
    "        return k / (k + math.exp(epoch / k))\n",
    "    else:\n",
    "        return 1.0  # ÈªòËÆ§ÂÖ®ÈÉ®‰ΩøÁî®teacher forcing\n",
    "\n",
    "rouge_calculator = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "\n",
    "model.config.use_cache = False\n",
    "optimizer = AdamW8bit(model.parameters(), lr=5e-4, weight_decay=0.01)\n",
    "num_epochs = 200\n",
    "gradient_accumulation_steps = 4\n",
    "scaler = torch.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Configuration for metric calculations\n",
    "rouge_calculation_frequency = 5  # Calculate RougeL every N epochs\n",
    "metric_strategy_threshold = 2  # Use different metrics based on epoch % N\n",
    "\n",
    "early_stop_patience = 10\n",
    "no_improve_epochs = 0\n",
    "best_val_metrics = {\"loss\": float(\"inf\"), \"rouge_l\": 0.0, \"perplexity\": float(\"inf\"), \"epoch\": 0}\n",
    "output_dir = \"./best_model_multi_eval_v2_correct_loss\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "label_smoothing_factor = 0.1\n",
    "training_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100, label_smoothing=label_smoothing_factor)\n",
    "\n",
    "num_update_steps_per_epoch = math.ceil(len(train_dataloader) / gradient_accumulation_steps)\n",
    "total_train_steps = num_epochs * num_update_steps_per_epoch\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"cosine\", optimizer=optimizer,\n",
    "    num_warmup_steps=int(0.1 * total_train_steps), num_training_steps=total_train_steps,\n",
    ")\n",
    "\n",
    "# Initialize metrics tracking for visualization\n",
    "metrics = {\n",
    "    'epoch': [],\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_perplexity': [],\n",
    "    'val_rouge_l': [],\n",
    "    'teacher_forcing_ratio': [],\n",
    "    'learning_rate': [],\n",
    "    'epoch_time': [],\n",
    "    'is_best': []\n",
    "}\n",
    "\n",
    "# For batch-level tracking\n",
    "batch_metrics = {\n",
    "    'global_step': [],\n",
    "    'batch_loss': [],\n",
    "    'learning_rate': []\n",
    "}\n",
    "\n",
    "print(f\"\\n--- Starting Training ---\")\n",
    "print(f\"Device: {device}, Epochs: {num_epochs}, Grad Accum: {gradient_accumulation_steps}\")\n",
    "print(f\"RougeL calculated every {rouge_calculation_frequency} epochs\")\n",
    "print(f\"Using scheduled sampling with linear decay strategy\")\n",
    "overall_progress_bar = tqdm(range(total_train_steps), desc=\"Training Progress\")\n",
    "\n",
    "global_step = 0\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    total_train_loss_for_epoch = 0.0\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    # Á°ÆÂÆöÂΩìÂâçepochÁöÑscheduled samplingÊØî‰æã\n",
    "    teacher_forcing_ratio = get_scheduled_sampling_ratio(epoch, num_epochs, strategy=\"inverse_sigmoid\")\n",
    "\n",
    "    # Á°ÆÂÆöÊòØÂê¶ËÆ°ÁÆóRougeL\n",
    "    calculate_rouge_this_epoch = (epoch % rouge_calculation_frequency == 0)\n",
    "\n",
    "    # Êõ¥Êñ∞ËøõÂ∫¶Êù°\n",
    "    overall_progress_bar.set_description(f\"Epoch {epoch}/{num_epochs} (TF={teacher_forcing_ratio:.2f})\")\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader, start=1):\n",
    "        input_ids = batch[\"input_ids\"].to(device, non_blocking=True)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
    "        labels = batch[\"labels\"].to(device, non_blocking=True)\n",
    "        decoder_input_ids = batch[\"decoder_input_ids\"].to(device, non_blocking=True)\n",
    "\n",
    "        # Ëé∑Âèñbatch‰∏≠ÁöÑÂ∫èÂàóÈïøÂ∫¶‰ø°ÊÅØ\n",
    "        if \"length\" in batch:\n",
    "            seq_lengths = batch[\"length\"].to(device, non_blocking=True)\n",
    "        else:\n",
    "            # Â¶ÇÊûúÊ≤°ÊúâÊèê‰æõlengthÔºåËÆ°ÁÆóÈùûpaddingÁöÑÈïøÂ∫¶\n",
    "            seq_lengths = (labels != -100).sum(dim=1)\n",
    "\n",
    "        # ÂÜ≥ÂÆöÊòØÂê¶‰ΩøÁî®scheduled sampling\n",
    "        use_scheduled_sampling = teacher_forcing_ratio < 1.0 and np.random.random() >= teacher_forcing_ratio\n",
    "\n",
    "        if use_scheduled_sampling:\n",
    "            # ----- Scheduled SamplingÂÆûÁé∞ -----\n",
    "            batch_size = input_ids.size(0)\n",
    "\n",
    "            # Ëé∑ÂèñÊ†áÁ≠æÂΩ¢Áä∂‰ø°ÊÅØ\n",
    "            tgt_len = labels.size(1)\n",
    "\n",
    "            # ‰ªéÁ¨¨‰∏Ä‰∏™tokenÂºÄÂßã\n",
    "            curr_decoder_input_ids = decoder_input_ids[:, :1].clone()\n",
    "\n",
    "            # ÈÄêÊ≠•ÁîüÊàêÂ∫èÂàóÂπ∂ËÆ°ÁÆóÊçüÂ§±\n",
    "            with torch.amp.autocast(dtype=torch.bfloat16, device_type=\"cuda\", enabled=torch.cuda.is_available()):\n",
    "                # È¶ñÂÖàÂæóÂà∞ÂÆåÊï¥ÁöÑÈ¢ÑÊµãÂ∫èÂàó\n",
    "                for i in range(1, tgt_len):\n",
    "                    # ÂØπÂΩìÂâçÂ∫èÂàóËøõË°åÂâçÂêëËÆ°ÁÆó\n",
    "                    outputs = model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        decoder_input_ids=curr_decoder_input_ids,\n",
    "                        use_cache=False\n",
    "                    )\n",
    "\n",
    "                    # Ëé∑ÂèñÈ¢ÑÊµãÁöÑ‰∏ã‰∏Ä‰∏™token\n",
    "                    next_token_logits = outputs.logits[:, -1, :]\n",
    "                    next_token = torch.argmax(next_token_logits, dim=-1).unsqueeze(-1)\n",
    "\n",
    "                    # Ê∑ªÂä†Âà∞Â∫èÂàó‰∏≠\n",
    "                    curr_decoder_input_ids = torch.cat([curr_decoder_input_ids, next_token], dim=1)\n",
    "\n",
    "                    # ÊèêÂâçÂÅúÊ≠¢ÔºàÂ¶ÇÊûúÊâÄÊúâÊ†∑Êú¨ÈÉΩËææÂà∞‰∫ÜÊúÄÂ§ßÈïøÂ∫¶Ôºâ\n",
    "                    if (i >= seq_lengths - 1).all().item():\n",
    "                        break\n",
    "\n",
    "                # ‰ΩøÁî®ÁîüÊàêÁöÑÂÆåÊï¥Â∫èÂàóËøõË°åÊúÄÁªàÁöÑÂâçÂêë‰º†Êí≠\n",
    "                final_outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    decoder_input_ids=curr_decoder_input_ids,\n",
    "                    use_cache=False\n",
    "                )\n",
    "\n",
    "                # ËÆ°ÁÆóÊçüÂ§±ÔºåÂ§ÑÁêÜÂ∫èÂàóÈïøÂ∫¶‰∏çÂåπÈÖçÁöÑÊÉÖÂÜµ\n",
    "                final_logits = final_outputs.logits\n",
    "\n",
    "                # Á°Æ‰øùlabelsÂíålogitsÂΩ¢Áä∂ÂåπÈÖç\n",
    "                if final_logits.size(1) < labels.size(1):\n",
    "                    # Â¶ÇÊûúÁîüÊàêÁöÑÂ∫èÂàóÊØîÊ†áÁ≠æÁü≠ÔºåÂè™‰ΩøÁî®ÁîüÊàêÁöÑÈÉ®ÂàÜ\n",
    "                    truncated_labels = labels[:, :final_logits.size(1)]\n",
    "                    loss = training_loss_fct(final_logits.reshape(-1, final_logits.size(-1)), truncated_labels.reshape(-1))\n",
    "                elif final_logits.size(1) > labels.size(1):\n",
    "                    # Â¶ÇÊûúÁîüÊàêÁöÑÂ∫èÂàóÊØîÊ†áÁ≠æÈïøÔºåÊâ©Â±ïÊ†áÁ≠æ\n",
    "                    padding = torch.full(\n",
    "                        (batch_size, final_logits.size(1) - labels.size(1)),\n",
    "                        -100, dtype=labels.dtype, device=labels.device\n",
    "                    )\n",
    "                    extended_labels = torch.cat([labels, padding], dim=1)\n",
    "                    loss = training_loss_fct(final_logits.reshape(-1, final_logits.size(-1)), extended_labels.reshape(-1))\n",
    "                else:\n",
    "                    # Â¶ÇÊûúÈïøÂ∫¶ÂåπÈÖç\n",
    "                    loss = training_loss_fct(final_logits.reshape(-1, final_logits.size(-1)), labels.reshape(-1))\n",
    "        else:\n",
    "            # ‰ΩøÁî®Ê†áÂáÜÁöÑteacher forcing\n",
    "            with torch.amp.autocast(dtype=torch.bfloat16, device_type=\"cuda\", enabled=torch.cuda.is_available()):\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    decoder_input_ids=decoder_input_ids,\n",
    "                    use_cache=False\n",
    "                )\n",
    "                logits = outputs.logits\n",
    "                loss = training_loss_fct(logits.reshape(-1, logits.size(-1)), labels.reshape(-1))\n",
    "\n",
    "        scaled_loss = loss / gradient_accumulation_steps\n",
    "        scaler.scale(scaled_loss).backward()\n",
    "        total_train_loss_for_epoch += loss.item()\n",
    "\n",
    "        # Track batch-level metrics\n",
    "        batch_metrics['global_step'].append(global_step)\n",
    "        batch_metrics['batch_loss'].append(loss.item())\n",
    "        batch_metrics['learning_rate'].append(lr_scheduler.get_last_lr()[0])\n",
    "\n",
    "        if (step % gradient_accumulation_steps == 0) or (step == len(train_dataloader)):\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            global_step += 1\n",
    "\n",
    "            # Êõ¥Êñ∞ËøõÂ∫¶Êù°\n",
    "            avg_loss_so_far = total_train_loss_for_epoch / step\n",
    "            overall_progress_bar.set_postfix({\n",
    "                \"loss\": f\"{avg_loss_so_far:.4f}\",\n",
    "                \"lr\": f\"{lr_scheduler.get_last_lr()[0]:.3e}\"\n",
    "            })\n",
    "            overall_progress_bar.update(1)\n",
    "\n",
    "        # Ê∏ÖÁêÜÂÜÖÂ≠ò\n",
    "        del input_ids, attention_mask, labels, decoder_input_ids, outputs, loss, scaled_loss\n",
    "        if use_scheduled_sampling:\n",
    "            del curr_decoder_input_ids, final_outputs, final_logits\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    avg_train_loss_epoch = total_train_loss_for_epoch / len(train_dataloader)\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "\n",
    "    overall_progress_bar.write(\n",
    "        f\"üöÄEpoch {epoch} - Avg Train Loss: {avg_train_loss_epoch:.4f} - \" +\n",
    "        f\"Time: {epoch_time:.2f}s - Teacher Forcing: {teacher_forcing_ratio:.2f}\"\n",
    "    )\n",
    "\n",
    "    # ÈÄöÁü•È™åËØÅÈò∂ÊÆµÂºÄÂßã\n",
    "    overall_progress_bar.write(\n",
    "        f\"Running validation for epoch {epoch}\" +\n",
    "        (f\" (with ROUGE-L)\" if calculate_rouge_this_epoch else \" (loss only)\")\n",
    "    )\n",
    "\n",
    "    # ËÆ°ÁÆóÈ™åËØÅÊåáÊ†á\n",
    "    validation_start_time = time.time()\n",
    "    current_val_metrics = calculate_metrics_on_validation(\n",
    "        model, tokenizer, eval_dataloader, device, rouge_calculator,\n",
    "        progress_bar=overall_progress_bar,\n",
    "        calculate_rouge=calculate_rouge_this_epoch\n",
    "    )\n",
    "    validation_time = time.time() - validation_start_time\n",
    "\n",
    "    # Á°Æ‰øùÊàë‰ª¨Êúârouge_lÂÄºÔºåÂç≥‰ΩøÊ≤°ÊúâÂú®Ëøô‰∏™epochËÆ°ÁÆó\n",
    "    if \"rouge_l\" not in current_val_metrics and epoch > 1:\n",
    "        # Â¶ÇÊûúÊúâÂèØÁî®ÁöÑÂâçÂÄºÔºå‰ΩøÁî®ÂÆÉ\n",
    "        current_val_metrics[\"rouge_l\"] = best_val_metrics.get(\"rouge_l\", 0.0)\n",
    "    elif \"rouge_l\" not in current_val_metrics:\n",
    "        current_val_metrics[\"rouge_l\"] = 0.0\n",
    "\n",
    "    # Á°ÆÂÆöÊòØÂê¶ÊòØÊúÄ‰Ω≥Ê®°Âûã\n",
    "    is_best = False\n",
    "    reason_for_best = \"\"\n",
    "\n",
    "    # ÂÅ∂Êï∞epoch: ‰ºòÂÖàËÄÉËôëÊçüÂ§±, Â•áÊï∞epoch: ‰ºòÂÖàËÄÉËôëRougeLÔºàÂ¶ÇÊûúÂèØÁî®Ôºâ\n",
    "    if epoch % metric_strategy_threshold == 0 and \"rouge_l\" in current_val_metrics:\n",
    "        # ÂÅ∂Êï∞epoch with RougeL: ÁªºÂêàÊåáÊ†á\n",
    "        rouge_improved = current_val_metrics[\"rouge_l\"] > best_val_metrics[\"rouge_l\"] + 0.0005\n",
    "        loss_improved_significantly = current_val_metrics[\"loss\"] < best_val_metrics[\"loss\"] * 0.98  # 2%ÊîπËøõ\n",
    "\n",
    "        if rouge_improved and current_val_metrics[\"loss\"] <= best_val_metrics[\"loss\"] * 1.05:  # ÂÖÅËÆ∏5%Êõ¥Â∑ÆÁöÑÊçüÂ§±\n",
    "            is_best = True\n",
    "            reason_for_best = f\"‚ÜëROUGE-L ({best_val_metrics['rouge_l']:.4f} ‚Üí {current_val_metrics['rouge_l']:.4f})\"\n",
    "        elif loss_improved_significantly and current_val_metrics[\"rouge_l\"] >= best_val_metrics[\"rouge_l\"] * 0.98:  # ÂÖÅËÆ∏2%Êõ¥Â∑ÆÁöÑROUGE\n",
    "            is_best = True\n",
    "            reason_for_best = f\"‚ÜëLoss ({best_val_metrics['loss']:.4f} ‚Üí {current_val_metrics['loss']:.4f})\"\n",
    "    else:\n",
    "        # Â•áÊï∞epochÊàñÊó†RougeL: ‰ºòÂÖàËÄÉËôëÈ™åËØÅÊçüÂ§±\n",
    "        if current_val_metrics[\"loss\"] < best_val_metrics[\"loss\"]:\n",
    "            is_best = True\n",
    "            reason_for_best = f\"‚ÜëLoss ({best_val_metrics['loss']:.4f} ‚Üí {current_val_metrics['loss']:.4f})\"\n",
    "\n",
    "    # Store metrics for visualization\n",
    "    metrics['epoch'].append(epoch)\n",
    "    metrics['train_loss'].append(avg_train_loss_epoch)\n",
    "    metrics['val_loss'].append(current_val_metrics[\"loss\"])\n",
    "    metrics['val_perplexity'].append(current_val_metrics[\"perplexity\"])\n",
    "    metrics['val_rouge_l'].append(current_val_metrics[\"rouge_l\"])\n",
    "    metrics['teacher_forcing_ratio'].append(teacher_forcing_ratio)\n",
    "    metrics['learning_rate'].append(lr_scheduler.get_last_lr()[0])\n",
    "    metrics['epoch_time'].append(epoch_time)\n",
    "    metrics['is_best'].append(is_best)\n",
    "\n",
    "    if is_best:\n",
    "        best_val_metrics = current_val_metrics.copy()\n",
    "        best_val_metrics[\"epoch\"] = epoch\n",
    "        no_improve_epochs = 0\n",
    "\n",
    "        # ‰øùÂ≠òÊ®°Âûã\n",
    "        model.save_pretrained(output_dir, save_embedding_layers=True)\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "        # Save training metrics as JSON at checkpoint\n",
    "        metrics_path = os.path.join(output_dir, \"training_metrics.json\")\n",
    "        with open(metrics_path, \"w\") as f:\n",
    "            json.dump(metrics, f, indent=2)\n",
    "\n",
    "        with open(os.path.join(output_dir, \"best_metrics.txt\"), \"w\") as f:\n",
    "            f.write(f\"Best Model from Epoch: {epoch}\\nMetrics: {best_val_metrics}\\n\")\n",
    "\n",
    "        overall_progress_bar.write(\n",
    "            f\"‚úÖ Ep {epoch}: New best! {reason_for_best}. Loss: {best_val_metrics['loss']:.4f}, \"\n",
    "            f\"PPL: {best_val_metrics['perplexity']:.2f}\" +\n",
    "            (f\", ROUGE: {best_val_metrics['rouge_l']:.4f}\" if \"rouge_l\" in best_val_metrics else \"\") +\n",
    "            f\" - Val time: {validation_time:.2f}s\"\n",
    "        )\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "        overall_progress_bar.write(\n",
    "            f\"‚ùó Ep {epoch}: No improvement ({no_improve_epochs}). \"\n",
    "            f\"Best (Ep {best_val_metrics['epoch']}): Loss {best_val_metrics['loss']:.4f}, \"\n",
    "            f\"PPL {best_val_metrics['perplexity']:.2f}\" +\n",
    "            (f\", ROUGE {best_val_metrics['rouge_l']:.4f}\" if \"rouge_l\" in best_val_metrics else \"\") +\n",
    "            f\" - Val time: {validation_time:.2f}s\"\n",
    "        )\n",
    "\n",
    "        if no_improve_epochs >= early_stop_patience:\n",
    "            overall_progress_bar.write(f\"‚õî Early stopping at Epoch {epoch}.\")\n",
    "            break\n",
    "\n",
    "    # # Generate intermediate plots every 10 epochs\n",
    "    # if epoch % 50 == 0 or epoch == 1:\n",
    "    #     try:\n",
    "    #         create_sci_training_plots(metrics, output_dir, prefix=f\"training_epoch_{epoch}\", journal_format=\"nature\")\n",
    "    #         overall_progress_bar.write(f\"üìä Generated training plots at epoch {epoch}\")\n",
    "    #     except Exception as e:\n",
    "    #         overall_progress_bar.write(f\"Warning: Could not generate plots: {e}\")\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "overall_progress_bar.close()\n",
    "print(\"\\n===== Training Complete =====\")\n",
    "\n",
    "# Generate final training visualization plots\n",
    "# try:\n",
    "#     create_sci_training_plots(metrics, output_dir, prefix=\"final_training\", journal_format=\"nature\")\n",
    "#     print(\"üìä Final training plots generated successfully\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Warning: Could not generate final plots: {e}\")\n",
    "\n",
    "# Save full training metrics\n",
    "metrics_path = os.path.join(output_dir, \"final_training_metrics.json\")\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "if best_val_metrics[\"epoch\"] > 0:\n",
    "    print(f\"Best model (Ep {best_val_metrics['epoch']}) saved to '{output_dir}'. Metrics: {best_val_metrics}\")\n",
    "else:\n",
    "    print(f\"No best model saved. Check '{output_dir}'.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-07T11:17:22.985453Z",
     "end_time": "2025-06-07T12:34:23.989493Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_sci_training_plots(metrics_data, output_dir, prefix=\"training\", journal_format=\"nature\"):\n",
    "    \"\"\"\n",
    "    Create publication-quality plots of training metrics optimized for SCI journals\n",
    "\n",
    "    Args:\n",
    "        metrics_data: Dictionary containing training metrics\n",
    "        output_dir: Directory to save plots\n",
    "        prefix: Prefix for saved files\n",
    "        journal_format: Journal style preset ('nature', 'science', 'ieee', 'elsevier')\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from matplotlib.gridspec import GridSpec\n",
    "    from cycler import cycler\n",
    "    import matplotlib as mpl\n",
    "\n",
    "    # Create directory for plots\n",
    "    plots_dir = os.path.join(output_dir, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "    # Set fixed DPI and formats\n",
    "    DPI = 300\n",
    "    FORMATS = [\"jpg\", \"PNG\"]\n",
    "\n",
    "    # Journal-specific formatting presets - refined for SCI journal standards and adjusted for larger figure size\n",
    "    journal_formats = {\n",
    "        \"default\": {\n",
    "            \"figsize\": (12, 15),\n",
    "            \"fontfamily\": \"serif\",\n",
    "            \"fontname\": \"Times New Roman\",\n",
    "            \"fontsize\": 13,\n",
    "            \"labelsize\": 15,\n",
    "            \"titlesize\": 17,\n",
    "            \"linewidth\": 2.25,\n",
    "            \"markersize\": 120,\n",
    "            \"colors\": [\"#0072B2\", \"#D55E00\", \"#009E73\", \"#CC79A7\", \"#F0E442\", \"#56B4E9\"],\n",
    "        },\n",
    "        \"nature\": {\n",
    "            \"figsize\": (12, 15),\n",
    "            \"fontfamily\": \"sans-serif\",\n",
    "            \"fontname\": \"Times New Roman\",\n",
    "            \"fontsize\": 13,\n",
    "            \"labelsize\": 15,\n",
    "            \"titlesize\": 17,\n",
    "            \"linewidth\": 2.0,\n",
    "            \"markersize\": 110,\n",
    "            \"colors\": [\"#0072B2\", \"#D55E00\", \"#009E73\", \"#CC79A7\", \"#E69F00\", \"#56B4E9\"],\n",
    "        },\n",
    "        \"science\": {\n",
    "            \"figsize\": (12, 15),\n",
    "            \"fontfamily\": \"sans-serif\",\n",
    "            \"fontname\": \"Arial\",\n",
    "            \"fontsize\": 12,\n",
    "            \"labelsize\": 14,\n",
    "            \"titlesize\": 16,\n",
    "            \"linewidth\": 2.0,\n",
    "            \"markersize\": 110,\n",
    "            \"colors\": [\"#3C5488\", \"#DC0000\", \"#00A087\", \"#E64B35\", \"#8491B4\", \"#F39B7F\"],\n",
    "        },\n",
    "        \"ieee\": {\n",
    "            \"figsize\": (12, 15),\n",
    "            \"fontfamily\": \"serif\",\n",
    "            \"fontname\": \"Times New Roman\",\n",
    "            \"fontsize\": 11,\n",
    "            \"labelsize\": 13,\n",
    "            \"titlesize\": 15,\n",
    "            \"linewidth\": 2.0,\n",
    "            \"markersize\": 110,\n",
    "            \"colors\": [\"#0072B2\", \"#D55E00\", \"#009E73\", \"#CC79A7\", \"#F0E442\", \"#56B4E9\"],\n",
    "        },\n",
    "        \"elsevier\": {\n",
    "            \"figsize\": (12, 15),\n",
    "            \"fontfamily\": \"serif\",\n",
    "            \"fontname\": \"Times New Roman\",\n",
    "            \"fontsize\": 13,\n",
    "            \"labelsize\": 15,\n",
    "            \"titlesize\": 17,\n",
    "            \"linewidth\": 2.0,\n",
    "            \"markersize\": 110,\n",
    "            \"colors\": [\"#4477AA\", \"#EE6677\", \"#228833\", \"#CCBB44\", \"#66CCEE\", \"#AA3377\"],\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Get the specified journal format or default\n",
    "    fmt = journal_formats.get(journal_format, journal_formats[\"default\"])\n",
    "\n",
    "    # Set global plotting parameters optimized for scientific publication\n",
    "    plt.style.use('default')  # Reset to default style first\n",
    "    mpl.rcParams.update({\n",
    "        # Font settings\n",
    "        'font.family': fmt[\"fontfamily\"],\n",
    "        'font.{}'.format(fmt[\"fontfamily\"]): [fmt[\"fontname\"]],\n",
    "        'font.size': fmt[\"fontsize\"],\n",
    "        'axes.labelsize': fmt[\"labelsize\"],\n",
    "        'axes.titlesize': fmt[\"titlesize\"],\n",
    "        'xtick.labelsize': fmt[\"fontsize\"],\n",
    "        'ytick.labelsize': fmt[\"fontsize\"],\n",
    "        'legend.fontsize': fmt[\"fontsize\"],\n",
    "\n",
    "        # Figure settings\n",
    "        'figure.figsize': fmt[\"figsize\"],\n",
    "        'figure.dpi': DPI,\n",
    "        'figure.facecolor': 'white',\n",
    "        'figure.edgecolor': 'white',\n",
    "\n",
    "        # Axes settings\n",
    "        'axes.facecolor': 'white',\n",
    "        'axes.edgecolor': '#333333',\n",
    "        'axes.prop_cycle': cycler('color', fmt[\"colors\"]),\n",
    "        'axes.linewidth': 1.0,  # Increased from 0.8\n",
    "        'axes.grid': True,\n",
    "        'axes.axisbelow': True,  # Place grid behind data\n",
    "\n",
    "        # Grid settings - more visible grid lines\n",
    "        'grid.alpha': 0.5,\n",
    "        'grid.color': '#b0b0b0',\n",
    "        'grid.linestyle': '--',\n",
    "        'grid.linewidth': 1.0,  # Increased from 0.8\n",
    "\n",
    "        # Line settings\n",
    "        'lines.linewidth': fmt[\"linewidth\"],\n",
    "        'lines.markersize': fmt[\"markersize\"]/20,\n",
    "        'lines.markeredgewidth': 1.0,  # Increased from 0.8\n",
    "\n",
    "        # Tick settings\n",
    "        'xtick.major.size': 4.5,  # Increased from 3.5\n",
    "        'ytick.major.size': 4.5,  # Increased from 3.5\n",
    "        'xtick.minor.size': 2.5,  # Increased from 2\n",
    "        'ytick.minor.size': 2.5,  # Increased from 2\n",
    "        'xtick.major.pad': 4.5,  # Increased from 3.5\n",
    "        'ytick.major.pad': 4.5,  # Increased from 3.5\n",
    "        'xtick.color': '#333333',\n",
    "        'ytick.color': '#333333',\n",
    "        'xtick.direction': 'out',\n",
    "        'ytick.direction': 'out',\n",
    "        'xtick.major.width': 1.0,  # Increased from 0.8\n",
    "        'ytick.major.width': 1.0,  # Increased from 0.8\n",
    "        'xtick.minor.width': 0.8,  # Increased from 0.6\n",
    "        'ytick.minor.width': 0.8,  # Increased from 0.6\n",
    "\n",
    "        # Legend settings\n",
    "        'legend.frameon': True,\n",
    "        'legend.framealpha': 1.0,  # No transparency to avoid warnings\n",
    "        'legend.edgecolor': '#cccccc',\n",
    "        'legend.fancybox': True,\n",
    "\n",
    "        # Save settings\n",
    "        'savefig.bbox': 'tight',\n",
    "        'savefig.pad_inches': 0.1,  # Increased from 0.05\n",
    "        'savefig.dpi': DPI,\n",
    "        'savefig.transparent': False,  # Set to False for consistent white background\n",
    "    })\n",
    "\n",
    "    # For colorblind-friendly and grayscale-compatible plots\n",
    "    sns.set_palette(fmt[\"colors\"])\n",
    "\n",
    "    # Add colorblind-friendly and grayscale-friendly markers and line styles\n",
    "    markers = ['o', 's', '^', 'd', 'v', '<', '>']\n",
    "    linestyles = ['-', '--', ':', '-.', (0, (3, 1, 1, 1)), (0, (3, 1, 1, 1, 1, 1))]\n",
    "\n",
    "    # Extract metrics\n",
    "    epochs = metrics_data['epoch']\n",
    "    train_loss = metrics_data['train_loss']\n",
    "    val_loss = metrics_data['val_loss']\n",
    "    val_perplexity = metrics_data['val_perplexity']\n",
    "    val_rouge_l = metrics_data['val_rouge_l']\n",
    "    teacher_forcing = metrics_data['teacher_forcing_ratio']\n",
    "    learning_rates = metrics_data['learning_rate']\n",
    "    epoch_times = metrics_data['epoch_time']\n",
    "    is_best = metrics_data['is_best']\n",
    "\n",
    "    # Find best epochs\n",
    "    best_epochs = [e for i, e in enumerate(epochs) if is_best[i]]\n",
    "    best_val_losses = [val_loss[i] for i, e in enumerate(epochs) if is_best[i]]\n",
    "\n",
    "    # Create comprehensive plot with multiple metrics\n",
    "    fig = plt.figure(figsize=fmt[\"figsize\"], dpi=DPI, facecolor='white')\n",
    "\n",
    "    # Use a different approach for layout to avoid warnings\n",
    "    gs = GridSpec(3, 2, figure=fig)\n",
    "    gs.update(wspace=0.35, hspace=0.45)  # Adjusted spacing for larger figure\n",
    "\n",
    "    # 1.1 Loss curves (train vs validation)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.plot(epochs, train_loss, color=fmt[\"colors\"][0],\n",
    "             linestyle=linestyles[0], marker=markers[0], markevery=max(1, len(epochs)//10),\n",
    "             label='Training Loss', linewidth=fmt[\"linewidth\"])\n",
    "    ax1.plot(epochs, val_loss, color=fmt[\"colors\"][1],\n",
    "             linestyle=linestyles[1], marker=markers[1], markevery=max(1, len(epochs)//10),\n",
    "             label='Test Loss', linewidth=fmt[\"linewidth\"])\n",
    "\n",
    "    # Highlight best epochs\n",
    "    if best_epochs:\n",
    "        ax1.scatter(best_epochs, best_val_losses, c='gold', s=fmt[\"markersize\"],\n",
    "                   edgecolors='black', zorder=5, label='Best Models')\n",
    "\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.legend(loc='upper right', framealpha=1.0)  # No transparency\n",
    "    ax1.grid(True, linestyle='--', alpha=0.5, color='#b0b0b0', linewidth=1.0)\n",
    "    ax1.minorticks_on()\n",
    "    ax1.grid(True, which='minor', linestyle=':', alpha=0.3, color='#b0b0b0', linewidth=0.8)\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "\n",
    "    # 1.2 Perplexity and ROUGE-L\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    color = fmt[\"colors\"][2]\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Perplexity', color=color)\n",
    "    ax2.plot(epochs, val_perplexity, color=color,\n",
    "             linestyle=linestyles[0], marker=markers[2], markevery=max(1, len(epochs)//10),\n",
    "             linewidth=fmt[\"linewidth\"])\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "    ax2.set_ylim(bottom=0)  # Ensure y-axis starts at 0 or appropriate value\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.spines['right'].set_visible(False)\n",
    "\n",
    "    ax2_twin = ax2.twinx()\n",
    "    color = fmt[\"colors\"][3]\n",
    "    ax2_twin.set_ylabel('ROUGE-L Score', color=color)\n",
    "    ax2_twin.plot(epochs, val_rouge_l, color=color,\n",
    "             linestyle=linestyles[1], marker=markers[3], markevery=max(1, len(epochs)//10),\n",
    "             linewidth=fmt[\"linewidth\"])\n",
    "    ax2_twin.tick_params(axis='y', labelcolor=color)\n",
    "    ax2_twin.spines['top'].set_visible(False)\n",
    "    ax2_twin.spines['left'].set_visible(False)\n",
    "\n",
    "    # Fix for identical ylims - ensure there's always a reasonable range\n",
    "    top_value = max(max(val_rouge_l)*1.1, 0.1) if val_rouge_l and max(val_rouge_l) > 0 else 1.0\n",
    "    ax2_twin.set_ylim(bottom=0, top=top_value)\n",
    "\n",
    "    ax2.set_title('Validation Metrics: Perplexity and ROUGE-L')\n",
    "    ax2.grid(True, linestyle='--', alpha=0.5, color='#b0b0b0', linewidth=1.0)\n",
    "    ax2.minorticks_on()\n",
    "    ax2.grid(True, which='minor', linestyle=':', alpha=0.3, color='#b0b0b0', linewidth=0.8)\n",
    "\n",
    "    # 1.3 Teacher Forcing Ratio\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    ax3.plot(epochs, teacher_forcing, color=fmt[\"colors\"][4],\n",
    "             linestyle=linestyles[0], marker=markers[4], markevery=max(1, len(epochs)//10),\n",
    "             linewidth=fmt[\"linewidth\"])\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Teacher Forcing Ratio')\n",
    "    ax3.set_title('Teacher Forcing Schedule')\n",
    "    ax3.set_ylim(0, 1.05)\n",
    "    ax3.grid(True, linestyle='--', alpha=0.5, color='#b0b0b0', linewidth=1.0)\n",
    "    ax3.minorticks_on()\n",
    "    ax3.grid(True, which='minor', linestyle=':', alpha=0.3, color='#b0b0b0', linewidth=0.8)\n",
    "    ax3.spines['top'].set_visible(False)\n",
    "    ax3.spines['right'].set_visible(False)\n",
    "\n",
    "    # 1.4 Learning Rate\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    ax4.plot(epochs, learning_rates, color=fmt[\"colors\"][5],\n",
    "             linestyle=linestyles[0], marker=markers[5], markevery=max(1, len(epochs)//10),\n",
    "             linewidth=fmt[\"linewidth\"])\n",
    "    ax4.set_xlabel('Epoch')\n",
    "    ax4.set_ylabel('Learning Rate')\n",
    "    ax4.set_title('Learning Rate Schedule')\n",
    "    ax4.set_yscale('log')\n",
    "    ax4.grid(True, linestyle='--', alpha=0.5, color='#b0b0b0', linewidth=1.0)\n",
    "    ax4.minorticks_on()\n",
    "    ax4.grid(True, which='minor', linestyle=':', alpha=0.3, color='#b0b0b0', linewidth=0.8)\n",
    "    ax4.spines['top'].set_visible(False)\n",
    "    ax4.spines['right'].set_visible(False)\n",
    "\n",
    "    # 1.5 Training time per epoch\n",
    "    ax5 = fig.add_subplot(gs[2, 0])\n",
    "    bars = ax5.bar(epochs, epoch_times, color=fmt[\"colors\"][0], alpha=0.7,\n",
    "            edgecolor='black', linewidth=0.8, width=0.7)\n",
    "\n",
    "    # Add light value labels above bars\n",
    "    if len(epochs) <= 15:  # Only add labels if not too crowded\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax5.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                    f'{int(height)}', ha='center', va='bottom',\n",
    "                    fontsize=fmt[\"fontsize\"]-1, alpha=1.0)  # No transparency\n",
    "\n",
    "    ax5.set_xlabel('Epoch')\n",
    "    ax5.set_ylabel('Time (seconds)')\n",
    "    ax5.set_title('Training Time per Epoch')\n",
    "    ax5.grid(True, linestyle='--', alpha=0.5, color='#b0b0b0', linewidth=1.0, axis='y')\n",
    "    ax5.spines['top'].set_visible(False)\n",
    "    ax5.spines['right'].set_visible(False)\n",
    "\n",
    "    # 1.6 Best models distribution\n",
    "    ax6 = fig.add_subplot(gs[2, 1])\n",
    "    if best_epochs:\n",
    "        diff_epochs = np.diff([0] + best_epochs)\n",
    "        bars = ax6.bar(range(len(diff_epochs)), diff_epochs, color=fmt[\"colors\"][1], alpha=0.7,\n",
    "                edgecolor='black', linewidth=0.8, width=0.7)\n",
    "\n",
    "        # Removed the value labels above bars as requested\n",
    "\n",
    "        ax6.set_xlabel('Best Model Index')\n",
    "        ax6.set_ylabel('Epochs Between Best Models')\n",
    "        ax6.set_title('Training Progress Pace')\n",
    "        ax6.grid(True, linestyle='--', alpha=0.5, color='#b0b0b0', linewidth=1.0, axis='y')\n",
    "        ax6.spines['top'].set_visible(False)\n",
    "        ax6.spines['right'].set_visible(False)\n",
    "    else:\n",
    "        ax6.text(0.5, 0.5, \"No best models recorded\",\n",
    "                 horizontalalignment='center', verticalalignment='center',\n",
    "                 fontsize=fmt[\"fontsize\"]+2)  # Increased fontsize for empty plot message\n",
    "        ax6.set_title('Training Progress Pace')\n",
    "        ax6.spines['top'].set_visible(False)\n",
    "        ax6.spines['right'].set_visible(False)\n",
    "\n",
    "    # Add overall title but don't use tight_layout which causes warnings\n",
    "    fig.suptitle('Training Process Metrics', fontsize=fmt[\"titlesize\"]+4, y=0.98)  # Increased suptitle size\n",
    "\n",
    "    # Use subplots_adjust instead of tight_layout to avoid warnings\n",
    "    fig.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.92)\n",
    "\n",
    "    # Save only as JPG and PNG as requested\n",
    "    for format_type in FORMATS:\n",
    "        plt.savefig(f\"{plots_dir}/{prefix}_combined.{format_type}\",\n",
    "                   dpi=DPI, bbox_inches='tight',\n",
    "                   facecolor='white', edgecolor='none')\n",
    "\n",
    "    # Close figure to free memory\n",
    "    plt.close(fig)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-07T12:34:24.010496Z",
     "end_time": "2025-06-07T12:34:24.016990Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "#\n",
    "# with open('./best_model_multi_eval_v3_correct_loss/training_metrics', 'w') as f:\n",
    "#     json.dump(metrics, f)\n",
    "output_dir=\"./best_model_multi_eval_v3_correct_loss\"\n",
    "# ËØªÂèñÂ≠óÂÖ∏\n",
    "with open('./best_model_multi_eval_v3_correct_loss/training_metrics', 'r') as f:\n",
    "    loaded_dict = json.load(f)\n",
    "create_sci_training_plots(loaded_dict, output_dir, prefix=\"final_training\", journal_format=\"nature\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-07T12:34:24.020498Z",
     "end_time": "2025-06-07T12:34:26.932486Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
